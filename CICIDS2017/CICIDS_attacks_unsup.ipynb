{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CICIDS 2017\n",
    "Implementación de los IDS separadamente para cada ataque usando algoritmos de aprendizaje no supervisado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File              ML algorithm                 Accuracy        Precision       Recall          F1-score        Time           \n",
      "Bot               K-Means                      0.64            0.34            0.45            0.39            0.0394         \n",
      "DDoS              K-Means                      0.77            0.73            0.69            0.7             0.22           \n",
      "DoS GoldenEye     K-Means                      0.73            0.7             0.58            0.57            0.0541         \n",
      "DoS Hulk          K-Means                      0.85            0.82            0.8             0.81            1.7521         \n",
      "DoS Slowhttptest  K-Means                      0.72            0.69            0.52            0.47            0.0349         \n",
      "DoS slowloris     K-Means                      0.66            0.34            0.47            0.4             0.0434         \n",
      "FTP-Patator       K-Means                      0.64            0.34            0.46            0.39            0.0736         \n",
      "Heartbleed        K-Means                      1.0             1.0             1.0             1.0             0.0215         \n",
      "Infiltration      K-Means                      0.83            0.78            0.83            0.8             0.0214         \n",
      "PortScan          K-Means                      0.64            0.35            0.45            0.39            0.8482         \n",
      "SSH-Patator       K-Means                      0.64            0.34            0.46            0.39            0.039          \n",
      "Web Attack        K-Means                      0.7             0.79            0.52            0.46            0.0276         \n",
      "mission accomplished!\n",
      "Total operation time: =  38.70964217185974 seconds\n"
     ]
    }
   ],
   "source": [
    "## NO SUPERVISADO: K-MEDIAS\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.cluster import completeness_score\n",
    "\n",
    "#Añadimos nuevos algoritmos de clasificación (no supervisado):\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import matplotlib as mpl\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler  #Escalar\n",
    "from sklearn.preprocessing import StandardScaler #Estandarizar\n",
    "from sklearn.preprocessing import Normalizer #Normalizar\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=50)\n",
    "#%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "import warnings\n",
    "import math\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "csv_files=os.listdir(\"attacks\")# CSV files names: #The names of the files in the attacks folder are taken and assigned to a list (csv_files).\n",
    "path=\".\\\\attacks\\\\\"\n",
    "repetition=10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# the features to be used for each attack type is defined in a dictionary(features).\n",
    "# the first 4 of the features created by the file \"04_1_feature_selection_for_attack_files.py\" are used here.\n",
    "features={\"Bot\":[\"Bwd Packet Length Mean\",\"Flow IAT Max\",\"Flow Duration\",\"Flow IAT Mean\",\"Label\"],\n",
    "\"DDoS\":[\"Bwd Packet Length Std\",\"Total Backward Packets\",\"Fwd IAT Total\",\"Total Length of Fwd Packets\",\"Label\"],\n",
    "\"DoS GoldenEye\":[\"Flow IAT Max\",\"Bwd Packet Length Std\",\"Flow IAT Min\",\"Total Backward Packets\",\"Label\"],\n",
    "\"DoS Hulk\":[\"Bwd Packet Length Std\",\"Fwd Packet Length Std\",\"Fwd Packet Length Max\",\"Flow IAT Min\",\"Label\"],\n",
    "\"DoS Slowhttptest\":[\"Flow IAT Mean\",\"Fwd Packet Length Min\",\"Fwd Packet Length Std\",\"Fwd Packet Length Mean\",\"Label\"],\n",
    "\"DoS slowloris\":[\"Flow IAT Mean\",\"Total Length of Bwd Packets\",\"Bwd Packet Length Mean\",\"Total Fwd Packets\",\"Label\"],\n",
    "\"FTP-Patator\":[\"Fwd Packet Length Max\",\"Fwd Packet Length Std\",\"Fwd Packet Length Mean\",\"Bwd Packet Length Mean\",\"Label\"],\n",
    "\"Heartbleed\":[\"Bwd Packet Length Mean\",\"Total Backward Packets\",\"Total Length of Bwd Packets\",\"Bwd Packet Length Max\",\"Label\"],\n",
    "\"Infiltration\":[\"Fwd Packet Length Max\",\"Fwd Packet Length Mean\",\"Flow Duration\",\"Total Length of Fwd Packets\",\"Label\"],\n",
    "\"PortScan\":[\"Flow Bytes/s\",\"Total Length of Fwd Packets\",\"Flow IAT Max\",\"Flow Duration\",\"Label\"],\n",
    "\"SSH-Patator\":[\"Fwd Packet Length Max\",\"Flow Duration\",\"Flow IAT Max\",\"Flow IAT Mean\",\"Label\"],\n",
    "\"Web Attack\":[\"Bwd Packet Length Std\",\"Total Length of Fwd Packets\",\"Flow Bytes/s\",\"Flow IAT Min\",\"Label\"]}\n",
    "\n",
    "seconds=time.time()#time stamp for all processing time\n",
    "\n",
    "\n",
    "print ('%-17s %-27s  %-15s %-15s %-15s %-15s %-15s' % (\"File\",\"ML algorithm\",\"Accuracy\",\"Precision\", \"Recall\" , \"F1-score\",\"Time\"))# print output header\n",
    "\n",
    "\n",
    "for j in csv_files: #this loop runs on the list containing the filenames.Operations are repeated for all attack files\n",
    "    a=[]\n",
    "    \n",
    "    feature_list=list(features[j[0:-4]])\n",
    "    df=pd.read_csv(path+j,usecols=feature_list)#read an attack file.\n",
    "    df=df.fillna(0)\n",
    "    attack_or_not=[]\n",
    "    for i in df[\"Label\"]: #it changes the normal label to \"1\" and the attack tag to \"0\" for use in the machine learning algorithm\n",
    "        \n",
    "        if i ==\"BENIGN\":\n",
    "            attack_or_not.append(1)\n",
    "        else:\n",
    "            attack_or_not.append(0)\n",
    "    df[\"Label\"]=attack_or_not\n",
    "\n",
    "    \n",
    "    y = df[\"Label\"] #this section separates the label and the data into two separate pieces, as Label=y Data=X \n",
    "    del df[\"Label\"]\n",
    "    feature_list.remove('Label')\n",
    "    X = df[feature_list]\n",
    "    \n",
    "    precision=[]\n",
    "    recall=[]\n",
    "    f1=[]\n",
    "    accuracy=[]\n",
    "    t_time=[]\n",
    "    \n",
    "    for i in range(repetition): # This loop allows cross-validation and machine learning algorithm to be repeated 10 times\n",
    "        #for i in range(repetition): # This loop allows cross-validation and machine learning algorithm to be repeated 10 times\n",
    "        second=time.time()#time stamp for processing time\n",
    "\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "        # cross-validation\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y,#  data (X) and labels (y) are divided into 2 parts to be sent to the machine learning algorithm (80% train,%20 test). \n",
    "            test_size = 0.20, random_state = repetition)#  So, in total there are 4 tracks: training data(X_train), training tag (y_train), test data(X_test) and test tag(y_test).\n",
    "\n",
    "        #print(\"  Numero de clusters: %d\\n\" % (2))\n",
    "        km = KMeans(init='random', n_clusters=2, random_state=333)\n",
    "        km.fit(X_train)     \n",
    "        predict = km.predict(X_test)\n",
    "\n",
    "        #Para poder identificar qué cluster corresponde\n",
    "        sum0 = sum(1 for p in predict if p == 0)\n",
    "        sum1 = sum(1 for p in predict if p == 1)\n",
    "        if(sum0 > sum1):\n",
    "            predict = predict + 1\n",
    "            predict = np.where(predict == 2, 0, predict)\n",
    "\n",
    "\n",
    "        f_1=f1_score(y_test, predict, average='macro')\n",
    "        pr=precision_score(y_test, predict, average='macro')\n",
    "        rc=recall_score(y_test, predict, average='macro')\n",
    "        score = metrics.accuracy_score(y_test, predict)\n",
    "\n",
    "        precision.append(float(pr))\n",
    "        recall.append(float(rc))\n",
    "        f1.append(float(f_1))\n",
    "        accuracy.append(score)\n",
    "        t_time.append(float((time.time()-second)))\n",
    "\n",
    "    print ('%-17s %-27s  %-15s %-15s %-15s %-15s %-15s' % (j[0:-4],\"K-Means\",str(round(np.mean(accuracy),2)),str(round(np.mean(precision),2)), \n",
    "            str(round(np.mean(recall),2)),str(round(np.mean(f1),2)),str(round(np.mean(t_time),4))))#the result of the ten repetitions is printed on the screen.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #print(\"\\n------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "    \n",
    "print(\"mission accomplished!\")\n",
    "print(\"Total operation time: = \",time.time()- seconds ,\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File              ML algorithm                 Accuracy        Precision       Recall          F1-score        Time           \n",
      "Bot               K-Medoids                    0.3             0.25            0.21            0.23            2.3309         \n",
      "DDoS              K-Medoids                    0.74            0.7             0.65            0.66            7.1836         \n",
      "DoS GoldenEye     K-Medoids                    0.86            0.87            0.81            0.83            10.5523        \n",
      "DoS Hulk          K-Medoids                    0.84            0.8             0.78            0.79            10.2076        \n",
      "DoS Slowhttptest  K-Medoids                    0.92            0.92            0.88            0.9             6.0754         \n",
      "DoS slowloris     K-Medoids                    0.61            0.33            0.44            0.38            5.6321         \n",
      "FTP-Patator       K-Medoids                    0.56            0.32            0.4             0.36            7.7878         \n",
      "Heartbleed        K-Medoids                    1.0             1.0             1.0             1.0             0.0176         \n",
      "Infiltration      K-Medoids                    0.58            0.5             0.5             0.5             0.0252         \n",
      "PortScan          K-Medoids                    0.64            0.35            0.45            0.39            11.4626        \n",
      "SSH-Patator       K-Medoids                    0.69            0.63            0.63            0.63            6.5162         \n",
      "Web Attack        K-Medoids                    0.55            0.37            0.42            0.39            4.1914         \n",
      "mission accomplished!\n",
      "Total operation time: =  728.7727069854736 seconds\n"
     ]
    }
   ],
   "source": [
    "## NO SUPERVISADO: K-MEDOIDS\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.cluster import completeness_score\n",
    "\n",
    "#Añadimos nuevos algoritmos de clasificación (no supervisado):\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import matplotlib as mpl\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler  #Escalar\n",
    "from sklearn.preprocessing import StandardScaler #Estandarizar\n",
    "from sklearn.preprocessing import Normalizer #Normalizar\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=50)\n",
    "#%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "import warnings\n",
    "import math\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "csv_files=os.listdir(\"attacks\")# CSV files names: #The names of the files in the attacks folder are taken and assigned to a list (csv_files).\n",
    "path=\".\\\\attacks\\\\\"\n",
    "repetition=10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# the features to be used for each attack type is defined in a dictionary(features).\n",
    "# the first 4 of the features created by the file \"04_1_feature_selection_for_attack_files.py\" are used here.\n",
    "features={\"Bot\":[\"Bwd Packet Length Mean\",\"Flow IAT Max\",\"Flow Duration\",\"Flow IAT Mean\",\"Label\"],\n",
    "\"DDoS\":[\"Bwd Packet Length Std\",\"Total Backward Packets\",\"Fwd IAT Total\",\"Total Length of Fwd Packets\",\"Label\"],\n",
    "\"DoS GoldenEye\":[\"Flow IAT Max\",\"Bwd Packet Length Std\",\"Flow IAT Min\",\"Total Backward Packets\",\"Label\"],\n",
    "\"DoS Hulk\":[\"Bwd Packet Length Std\",\"Fwd Packet Length Std\",\"Fwd Packet Length Max\",\"Flow IAT Min\",\"Label\"],\n",
    "\"DoS Slowhttptest\":[\"Flow IAT Mean\",\"Fwd Packet Length Min\",\"Fwd Packet Length Std\",\"Fwd Packet Length Mean\",\"Label\"],\n",
    "\"DoS slowloris\":[\"Flow IAT Mean\",\"Total Length of Bwd Packets\",\"Bwd Packet Length Mean\",\"Total Fwd Packets\",\"Label\"],\n",
    "\"FTP-Patator\":[\"Fwd Packet Length Max\",\"Fwd Packet Length Std\",\"Fwd Packet Length Mean\",\"Bwd Packet Length Mean\",\"Label\"],\n",
    "\"Heartbleed\":[\"Bwd Packet Length Mean\",\"Total Backward Packets\",\"Total Length of Bwd Packets\",\"Bwd Packet Length Max\",\"Label\"],\n",
    "\"Infiltration\":[\"Fwd Packet Length Max\",\"Fwd Packet Length Mean\",\"Flow Duration\",\"Total Length of Fwd Packets\",\"Label\"],\n",
    "\"PortScan\":[\"Flow Bytes/s\",\"Total Length of Fwd Packets\",\"Flow IAT Max\",\"Flow Duration\",\"Label\"],\n",
    "\"SSH-Patator\":[\"Fwd Packet Length Max\",\"Flow Duration\",\"Flow IAT Max\",\"Flow IAT Mean\",\"Label\"],\n",
    "\"Web Attack\":[\"Bwd Packet Length Std\",\"Total Length of Fwd Packets\",\"Flow Bytes/s\",\"Flow IAT Min\",\"Label\"]}\n",
    "\n",
    "seconds=time.time()#time stamp for all processing time\n",
    "\n",
    "print ('%-17s %-27s  %-15s %-15s %-15s %-15s %-15s' % (\"File\",\"ML algorithm\",\"Accuracy\",\"Precision\", \"Recall\" , \"F1-score\",\"Time\"))# print output header\n",
    "\n",
    "for j in csv_files: #this loop runs on the list containing the filenames.Operations are repeated for all attack files\n",
    "    a=[]\n",
    "    \n",
    "    feature_list=list(features[j[0:-4]])\n",
    "    df=pd.read_csv(path+j,usecols=feature_list)#read an attack file.\n",
    "    df=df.fillna(0)\n",
    "    numRows = min(df.shape[0]-1, 10000) #Para que no explote el consumo de memoria\n",
    "    df = df.sample(numRows)\n",
    "    attack_or_not=[]\n",
    "    for i in df[\"Label\"]: #it changes the normal label to \"1\" and the attack tag to \"0\" for use in the machine learning algorithm\n",
    "        \n",
    "        if i ==\"BENIGN\":\n",
    "            attack_or_not.append(1)\n",
    "        else:\n",
    "            attack_or_not.append(0)\n",
    "    df[\"Label\"]=attack_or_not\n",
    "\n",
    "    \n",
    "    y = df[\"Label\"] #this section separates the label and the data into two separate pieces, as Label=y Data=X \n",
    "    del df[\"Label\"]\n",
    "    feature_list.remove('Label')\n",
    "    X = df[feature_list]\n",
    "    \n",
    "    precision=[]\n",
    "    recall=[]\n",
    "    f1=[]\n",
    "    accuracy=[]\n",
    "    t_time=[]\n",
    "    \n",
    "    for i in range(repetition): # This loop allows cross-validation and machine learning algorithm to be repeated 10 times\n",
    "        #for i in range(repetition): # This loop allows cross-validation and machine learning algorithm to be repeated 10 times\n",
    "        second=time.time()#time stamp for processing time\n",
    "\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "        \n",
    "        # cross-validation\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y,#  data (X) and labels (y) are divided into 2 parts to be sent to the machine learning algorithm (80% train,%20 test). \n",
    "            test_size = 0.20, random_state = repetition)#  So, in total there are 4 tracks: training data(X_train), training tag (y_train), test data(X_test) and test tag(y_test).\n",
    "\n",
    "        #print(\"  Numero de clusters: %d\\n\" % (2))\n",
    "        km = KMedoids(init='random', n_clusters=2, random_state=333)\n",
    "        km.fit(X_train)     \n",
    "        predict = km.predict(X_test)\n",
    "\n",
    "        #Para poder identificar qué cluster corresponde\n",
    "        sum0 = sum(1 for p in predict if p == 0)\n",
    "        sum1 = sum(1 for p in predict if p == 1)\n",
    "        if(sum0 > sum1):\n",
    "            predict = predict + 1\n",
    "            predict = np.where(predict == 2, 0, predict)\n",
    "\n",
    "\n",
    "        f_1=f1_score(y_test, predict, average='macro')\n",
    "        pr=precision_score(y_test, predict, average='macro')\n",
    "        rc=recall_score(y_test, predict, average='macro')\n",
    "        score = metrics.accuracy_score(y_test, predict)\n",
    "\n",
    "        precision.append(float(pr))\n",
    "        recall.append(float(rc))\n",
    "        f1.append(float(f_1))\n",
    "        accuracy.append(score)\n",
    "        t_time.append(float((time.time()-second)))\n",
    "\n",
    "    print ('%-17s %-27s  %-15s %-15s %-15s %-15s %-15s' % (j[0:-4],\"K-Medoids\",str(round(np.mean(accuracy),2)),str(round(np.mean(precision),2)), \n",
    "            str(round(np.mean(recall),2)),str(round(np.mean(f1),2)),str(round(np.mean(t_time),4))))#the result of the ten repetitions is printed on the screen.\n",
    "\n",
    "    #print(\"\\n------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "    \n",
    "print(\"mission accomplished!\")\n",
    "print(\"Total operation time: = \",time.time()- seconds ,\"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File              ML algorithm                 Accuracy        Precision       Recall          F1-score        Time           \n",
      "Bot               Isolation Forest             0.54            0.44            0.44            0.44            0.0721         \n",
      "DDoS              Isolation Forest             0.67            0.61            0.61            0.61            0.3327         \n",
      "DoS GoldenEye     Isolation Forest             0.82            0.79            0.79            0.79            0.1249         \n",
      "DoS Hulk          Isolation Forest             0.64            0.57            0.57            0.57            2.1033         \n",
      "DoS Slowhttptest  Isolation Forest             0.66            0.59            0.59            0.59            0.1066         \n",
      "DoS slowloris     Isolation Forest             0.6             0.52            0.52            0.52            0.0949         \n",
      "FTP-Patator       Isolation Forest             0.4             0.28            0.29            0.28            0.1085         \n",
      "Heartbleed        Isolation Forest             0.57            0.54            0.55            0.53            0.0468         \n",
      "Infiltration      Isolation Forest             0.71            0.63            0.64            0.63            0.0431         \n",
      "PortScan          Isolation Forest             0.42            0.3             0.3             0.3             1.2928         \n",
      "SSH-Patator       Isolation Forest             0.58            0.5             0.5             0.5             0.0824         \n",
      "Web Attack        Isolation Forest             0.44            0.34            0.35            0.35            0.0598         \n",
      "mission accomplished!\n",
      "Total operation time: =  51.20529580116272 seconds\n"
     ]
    }
   ],
   "source": [
    "#NO SUPERVISADO: Isolation Forest\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.cluster import completeness_score\n",
    "\n",
    "#Añadimos nuevos algoritmos de clasificación (no supervisado):\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import matplotlib as mpl\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler  #Escalar\n",
    "from sklearn.preprocessing import StandardScaler #Estandarizar\n",
    "from sklearn.preprocessing import Normalizer #Normalizar\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "#%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "import warnings\n",
    "import math\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "csv_files=os.listdir(\"attacks\")# CSV files names: #The names of the files in the attacks folder are taken and assigned to a list (csv_files).\n",
    "path=\".\\\\attacks\\\\\"\n",
    "repetition=10\n",
    "\n",
    "ml_list={\n",
    "\"Isolation Forest\": IsolationForest(random_state=123, n_estimators = 30, contamination = 0.3, max_samples = \"auto\") #Sabemos que el 30% de los datos corresponden con ataques => contamination=0.3\n",
    "}\n",
    "\n",
    "\n",
    "# the features to be used for each attack type is defined in a dictionary(features).\n",
    "# the first 4 of the features created by the file \"04_1_feature_selection_for_attack_files.py\" are used here.\n",
    "features={\"Bot\":[\"Bwd Packet Length Mean\",\"Flow IAT Max\",\"Flow Duration\",\"Flow IAT Mean\",\"Label\"],\n",
    "\"DDoS\":[\"Bwd Packet Length Std\",\"Total Backward Packets\",\"Fwd IAT Total\",\"Total Length of Fwd Packets\",\"Label\"],\n",
    "\"DoS GoldenEye\":[\"Flow IAT Max\",\"Bwd Packet Length Std\",\"Flow IAT Min\",\"Total Backward Packets\",\"Label\"],\n",
    "\"DoS Hulk\":[\"Bwd Packet Length Std\",\"Fwd Packet Length Std\",\"Fwd Packet Length Max\",\"Flow IAT Min\",\"Label\"],\n",
    "\"DoS Slowhttptest\":[\"Flow IAT Mean\",\"Fwd Packet Length Min\",\"Fwd Packet Length Std\",\"Fwd Packet Length Mean\",\"Label\"],\n",
    "\"DoS slowloris\":[\"Flow IAT Mean\",\"Total Length of Bwd Packets\",\"Bwd Packet Length Mean\",\"Total Fwd Packets\",\"Label\"],\n",
    "\"FTP-Patator\":[\"Fwd Packet Length Max\",\"Fwd Packet Length Std\",\"Fwd Packet Length Mean\",\"Bwd Packet Length Mean\",\"Label\"],\n",
    "\"Heartbleed\":[\"Bwd Packet Length Mean\",\"Total Backward Packets\",\"Total Length of Bwd Packets\",\"Bwd Packet Length Max\",\"Label\"],\n",
    "\"Infiltration\":[\"Fwd Packet Length Max\",\"Fwd Packet Length Mean\",\"Flow Duration\",\"Total Length of Fwd Packets\",\"Label\"],\n",
    "\"PortScan\":[\"Flow Bytes/s\",\"Total Length of Fwd Packets\",\"Flow IAT Max\",\"Flow Duration\",\"Label\"],\n",
    "\"SSH-Patator\":[\"Fwd Packet Length Max\",\"Flow Duration\",\"Flow IAT Max\",\"Flow IAT Mean\",\"Label\"],\n",
    "\"Web Attack\":[\"Bwd Packet Length Std\",\"Total Length of Fwd Packets\",\"Flow Bytes/s\",\"Flow IAT Min\",\"Label\"]}\n",
    "\n",
    "\n",
    "seconds=time.time()#time stamp for all processing time\n",
    "\n",
    "print ('%-17s %-27s  %-15s %-15s %-15s %-15s %-15s' % (\"File\",\"ML algorithm\",\"Accuracy\",\"Precision\", \"Recall\" , \"F1-score\",\"Time\"))# print output header\n",
    "\n",
    "for j in csv_files: #this loop runs on the list containing the filenames.Operations are repeated for all attack files\n",
    "    a=[]\n",
    "    \n",
    "    feature_list=list(features[j[0:-4]])\n",
    "    df=pd.read_csv(path+j,usecols=feature_list)#read an attack file.\n",
    "    df=df.fillna(0)\n",
    "    attack_or_not=[]\n",
    "    for i in df[\"Label\"]: #it changes the normal label to \"1\" and the attack tag to \"0\" for use in the machine learning algorithm\n",
    "        \n",
    "        if i ==\"BENIGN\":\n",
    "            attack_or_not.append(1)\n",
    "        else:\n",
    "            attack_or_not.append(0)\n",
    "    df[\"Label\"]=attack_or_not\n",
    "\n",
    "    \n",
    "    y = df[\"Label\"] #this section separates the label and the data into two separate pieces, as Label=y Data=X \n",
    "    del df[\"Label\"]\n",
    "    feature_list.remove('Label')\n",
    "    X = df[feature_list]\n",
    "    \n",
    "\n",
    "    for ii in ml_list:\n",
    "        precision=[]\n",
    "        recall=[]\n",
    "        f1=[]\n",
    "        accuracy=[]\n",
    "        t_time=[]\n",
    "        \n",
    "        for i in range(repetition): # This loop allows cross-validation and machine learning algorithm to be repeated 10 times\n",
    "            #for i in range(repetition): # This loop allows cross-validation and machine learning algorithm to be repeated 10 times\n",
    "            second=time.time()#time stamp for processing time\n",
    "\n",
    "            # cross-validation\n",
    "            scaler = StandardScaler()\n",
    "            X = scaler.fit_transform(X)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y,#  data (X) and labels (y) are divided into 2 parts to be sent to the machine learning algorithm (80% train,%20 test). \n",
    "                test_size = 0.20, random_state = repetition)#  So, in total there are 4 tracks: training data(X_train), training tag (y_train), test data(X_test) and test tag(y_test).\n",
    "\n",
    "            #scaler = MinMaxScaler()\n",
    "            #scaler = StandardScaler()\n",
    "            #scaler = Normalizer()\n",
    "            #X_train = scaler.fit_transform(X_train)\n",
    "            #X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "            clf = ml_list[ii]#choose algorithm from ml_list dictionary                                                                          \n",
    "            clf.fit(X_train)\n",
    "            predict =clf.predict(X_test)\n",
    "\n",
    "            predict = np.where(predict == -1, 0, predict) #El resultado de isolation forest son 1 para los normales y -1 para anomalías\n",
    "\n",
    "            #makes \"classification report\" and assigns the precision, f-measure, and recall values.s.    \n",
    "            f_1=f1_score(y_test, predict, average='macro')\n",
    "            pr=precision_score(y_test, predict, average='macro')\n",
    "            rc=recall_score(y_test, predict, average='macro')\n",
    "            score = metrics.accuracy_score(y_test, predict)\n",
    "\n",
    "            precision.append(float(pr))\n",
    "            recall.append(float(rc))\n",
    "            f1.append(float(f_1))\n",
    "            accuracy.append(score)\n",
    "            t_time.append(float((time.time()-second)))\n",
    "\n",
    "        print ('%-17s %-27s  %-15s %-15s %-15s %-15s %-15s' % (j[0:-4],ii,str(round(np.mean(accuracy),2)),str(round(np.mean(precision),2)), \n",
    "                str(round(np.mean(recall),2)),str(round(np.mean(f1),2)),str(round(np.mean(t_time),4))))#the result of the ten repetitions is printed on the screen.\n",
    "\n",
    "\n",
    "    #print(\"\\n------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "    \n",
    "print(\"mission accomplished!\")\n",
    "print(\"Total operation time: = \",time.time()- seconds ,\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File              ML algorithm                 Accuracy        Precision       Recall          F1-score        Time           \n",
      "Bot               LOF                          0.57            0.42            0.44            0.42            0.0899         \n",
      "DDoS              LOF                          0.6             0.47            0.48            0.47            3.9223         \n",
      "DoS GoldenEye     LOF                          0.61            0.48            0.48            0.47            0.5521         \n",
      "DoS Hulk          LOF                          0.63            0.5             0.5             0.5             100.5955       \n",
      "DoS Slowhttptest  LOF                          0.57            0.41            0.43            0.42            0.4681         \n",
      "DoS slowloris     LOF                          0.56            0.41            0.43            0.42            0.3131         \n",
      "FTP-Patator       LOF                          0.61            0.49            0.49            0.48            0.8546         \n",
      "Heartbleed        LOF                          0.43            0.3             0.3             0.3             0.0383         \n",
      "Infiltration      LOF                          0.96            0.97            0.92            0.94            0.0383         \n",
      "PortScan          LOF                          0.52            0.33            0.36            0.34            22.7104        \n",
      "SSH-Patator       LOF                          0.55            0.38            0.41            0.39            0.2415         \n",
      "Web Attack        LOF                          0.5             0.33            0.38            0.35            0.092          \n",
      "mission accomplished!\n",
      "Total operation time: =  1308.234911441803 seconds\n"
     ]
    }
   ],
   "source": [
    "#NO SUPERVISADO: Local Outlier Factor\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.cluster import completeness_score\n",
    "\n",
    "#Añadimos nuevos algoritmos de clasificación (no supervisado):\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import matplotlib as mpl\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler  #Escalar\n",
    "from sklearn.preprocessing import StandardScaler #Estandarizar\n",
    "from sklearn.preprocessing import Normalizer #Normalizar\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "#%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "import warnings\n",
    "import math\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "csv_files=os.listdir(\"attacks\")# CSV files names: #The names of the files in the attacks folder are taken and assigned to a list (csv_files).\n",
    "path=\".\\\\attacks\\\\\"\n",
    "repetition=10\n",
    "\n",
    "ml_list={\n",
    "\"LOF\": LocalOutlierFactor(n_neighbors=25, contamination=0.2) #Sabemos que el 30% de los datos corresponden con ataques => contamination=0.3\n",
    "}\n",
    "\n",
    "\n",
    "# the features to be used for each attack type is defined in a dictionary(features).\n",
    "# the first 4 of the features created by the file \"04_1_feature_selection_for_attack_files.py\" are used here.\n",
    "features={\"Bot\":[\"Bwd Packet Length Mean\",\"Flow IAT Max\",\"Flow Duration\",\"Flow IAT Min\",\"Label\"],\n",
    "\"DDoS\":[\"Bwd Packet Length Std\",\"Total Backward Packets\",\"Fwd IAT Total\",\"Flow Duration\",\"Label\"],\n",
    "\"DoS GoldenEye\":[\"Flow IAT Max\",\"Bwd Packet Length Std\",\"Flow IAT Min\",\"Total Backward Packets\",\"Label\"],\n",
    "\"DoS Hulk\":[\"Bwd Packet Length Std\",\"Fwd Packet Length Std\",\"Fwd Packet Length Max\",\"Flow IAT Min\",\"Label\"],\n",
    "\"DoS Slowhttptest\":[\"Flow IAT Mean\",\"Fwd Packet Length Min\",\"Bwd Packet Length Mean\",\"Total Length of Bwd Packets\",\"Label\"],\n",
    "\"DoS slowloris\":[\"Flow IAT Mean\",\"Total Length of Bwd Packets\",\"Bwd Packet Length Mean\",\"Total Fwd Packets\",\"Label\"],\n",
    "\"FTP-Patator\":[\"Fwd Packet Length Max\",\"Fwd Packet Length Std\",\"Fwd Packet Length Mean\",\"Bwd Packet Length Std\",\"Label\"],\n",
    "\"Heartbleed\":[\"Total Backward Packets\",\"Fwd Packet Length Max\",\"Flow IAT Min\",\"Bwd Packet Length Max\",\"Label\"],\n",
    "\"Infiltration\":[\"Fwd Packet Length Max\",\"Fwd Packet Length Mean\",\"Flow Duration\",\"Total Length of Fwd Packets\",\"Label\"],\n",
    "\"PortScan\":[\"Flow Bytes/s\",\"Total Length of Fwd Packets\",\"Fwd IAT Total\",\"Flow Duration\",\"Label\"],\n",
    "\"SSH-Patator\":[\"Fwd Packet Length Max\",\"Flow Duration\",\"Flow IAT Max\",\"Total Length of Fwd Packets\",\"Label\"],\n",
    "\"Web Attack\":[\"Bwd Packet Length Std\",\"Total Length of Fwd Packets\",\"Flow Bytes/s\",\"Flow IAT Max\",\"Label\"]}\n",
    "\n",
    "seconds=time.time()#time stamp for all processing time\n",
    "\n",
    "print ('%-17s %-27s  %-15s %-15s %-15s %-15s %-15s' % (\"File\",\"ML algorithm\",\"Accuracy\",\"Precision\", \"Recall\" , \"F1-score\",\"Time\"))# print output header\n",
    "for j in csv_files: #this loop runs on the list containing the filenames.Operations are repeated for all attack files\n",
    "    a=[]\n",
    "    \n",
    "    feature_list=list(features[j[0:-4]])\n",
    "    df=pd.read_csv(path+j,usecols=feature_list)#read an attack file.\n",
    "    df=df.fillna(0)\n",
    "    attack_or_not=[]\n",
    "    for i in df[\"Label\"]: #it changes the normal label to \"1\" and the attack tag to \"0\" for use in the machine learning algorithm\n",
    "        \n",
    "        if i ==\"BENIGN\":\n",
    "            attack_or_not.append(1)\n",
    "        else:\n",
    "            attack_or_not.append(0)\n",
    "    df[\"Label\"]=attack_or_not\n",
    "\n",
    "    \n",
    "    y = df[\"Label\"] #this section separates the label and the data into two separate pieces, as Label=y Data=X \n",
    "    del df[\"Label\"]\n",
    "    feature_list.remove('Label')\n",
    "    X = df[feature_list]\n",
    "    \n",
    "\n",
    "    for ii in ml_list:\n",
    "        precision=[]\n",
    "        recall=[]\n",
    "        f1=[]\n",
    "        accuracy=[]\n",
    "        t_time=[]\n",
    "        \n",
    "        for i in range(repetition): # This loop allows cross-validation and machine learning algorithm to be repeated 10 times\n",
    "            #for i in range(repetition): # This loop allows cross-validation and machine learning algorithm to be repeated 10 times\n",
    "            second=time.time()#time stamp for processing time\n",
    "\n",
    "            # cross-validation\n",
    "            scaler = StandardScaler()\n",
    "            X = scaler.fit_transform(X)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y,#  data (X) and labels (y) are divided into 2 parts to be sent to the machine learning algorithm (80% train,%20 test). \n",
    "                test_size = 0.20, random_state = repetition)#  So, in total there are 4 tracks: training data(X_train), training tag (y_train), test data(X_test) and test tag(y_test).\n",
    "\n",
    "            clf = ml_list[ii]#choose algorithm from ml_list dictionary                                                                          \n",
    "            clf.fit(X_train)\n",
    "            predict =clf.fit_predict(X_test)\n",
    "\n",
    "            predict = np.where(predict == -1, 0, predict) #El resultado de LOF son 1 para los normales y -1 para anomalías\n",
    "\n",
    "            #makes \"classification report\" and assigns the precision, f-measure, and recall values.s.    \n",
    "            f_1=f1_score(y_test, predict, average='macro')\n",
    "            pr=precision_score(y_test, predict, average='macro')\n",
    "            rc=recall_score(y_test, predict, average='macro')\n",
    "            score = metrics.accuracy_score(y_test, predict)\n",
    "\n",
    "            precision.append(float(pr))\n",
    "            recall.append(float(rc))\n",
    "            f1.append(float(f_1))\n",
    "            accuracy.append(score)\n",
    "            t_time.append(float((time.time()-second)))\n",
    "\n",
    "        print ('%-17s %-27s  %-15s %-15s %-15s %-15s %-15s' % (j[0:-4],ii,str(round(np.mean(accuracy),2)),str(round(np.mean(precision),2)), \n",
    "                str(round(np.mean(recall),2)),str(round(np.mean(f1),2)),str(round(np.mean(t_time),4))))#the result of the ten repetitions is printed on the screen\n",
    "\n",
    "\n",
    "    #print(\"\\n------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "    \n",
    "print(\"mission accomplished!\")\n",
    "print(\"Total operation time: = \",time.time()- seconds ,\"seconds\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
