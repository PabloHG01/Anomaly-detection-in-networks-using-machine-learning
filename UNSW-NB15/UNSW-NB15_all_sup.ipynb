{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNSW-NB15\n",
    "Implementación de los IDS para el conjunto total de datos usando algoritmos de aprendizaje supervisado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File              ML algorithm       accuracy        Precision       Recall          F1-score        Time           \n",
      "all_data_preproc  Naive Bayes        0.86            0.59            0.52            0.51            2.2354         \n",
      "all_data_preproc  QDA                0.87            0.66            0.55            0.56            2.4654         \n",
      "all_data_preproc  Random Forest      0.98            0.98            0.91            0.94            19.0587        \n",
      "all_data_preproc  ID3                0.98            0.98            0.95            0.96            9.4779         \n",
      "all_data_preproc  AdaBoost           0.99            0.97            0.97            0.97            165.1903       \n",
      "all_data_preproc  MLP                0.87            0.92            0.5             0.47            133.4903       \n",
      "all_data_preproc  Nearest Neighbors  0.99            0.97            0.97            0.97            132.4598       \n",
      "Cálculo completado\n",
      "Tiempo total de ejecución: =  4652.039316654205 segundos\n"
     ]
    }
   ],
   "source": [
    "####  ALL_DATA: 7 LABELS - P1 ALGORITHMS\n",
    "\n",
    "#  Se requiere el archivo all_data_preproc.csv para la ejecución de este código.\n",
    "#  El archivo all_data_preproc.csv debe estar ubicado en el mismo directorio que el programa.\n",
    "\n",
    "#   El objetivo de este código es aplicar algoritmos de aprendizaje automático al dataset y observar su desempeño\n",
    "#   Los algoritmos usados son: Naive Bayes, QDA, Random Forest, ID3, AdaBoost, MLP y K Nearest Neighbors\n",
    "#   Las medidas de rendimiento calculadas y mostradas son accuracy, precision, recall y F1-score. También se recoge para cada uno el tiempo que ha tardado en calcular.\n",
    "#   Se creará también un archivo CSV (results_1.csv) con los resultados y un directorio (result_graph) con los correspondientes gráficos\n",
    "\n",
    "##  the some codes parts used for calculation and graphing are taken from the following site.\n",
    "##  http://scikit-learn.org\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "import warnings\n",
    "import math\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "result=\"./results/results_2.csv\" #a CSV file is named in which the results are saved.\n",
    "csv_files=[\"all_data_preproc.csv\"]# CSV files names: #The names of the dataset files (csv_files).\n",
    "path=\"\"\n",
    "repetition=10\n",
    "\n",
    "\n",
    "def folder(f_name):\n",
    "    try:\n",
    "        if not os.path.exists(f_name):\n",
    "            os.makedirs(f_name)\n",
    "    except OSError:\n",
    "        print (\"The folder could not be created!\")\n",
    "\n",
    "folder_name=\"./results/\"\n",
    "folder(folder_name)\n",
    "folder_name=\"./results/result_graph_1/\"\n",
    "folder(folder_name)\n",
    "\n",
    "\n",
    "#   Los algoritmos utilizados se manejarán con una diccionario:\n",
    "ml_list={\n",
    "\"Naive Bayes\":GaussianNB(),\n",
    "\"QDA\":QDA(),\n",
    "\"Random Forest\":RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "\"ID3\" :DecisionTreeClassifier(max_depth=5,criterion=\"entropy\"),\n",
    "\"AdaBoost\":AdaBoostClassifier(),\n",
    "\"MLP\":MLPClassifier(hidden_layer_sizes=(13,13,13),max_iter=500),\n",
    "\"Nearest Neighbors\":KNeighborsClassifier(3)}\n",
    "\n",
    "\n",
    "features={  'all_data_preproc': [\"dsport\", \"sbytes\", \"sport\", \"Sload\", \"dbytes\", \"Spkts\", \"dstip\", \"Label\"]}\n",
    "\n",
    "seconds=time.time() #Para calcular el tiempo de cálculo\n",
    "\n",
    "\n",
    "with open(result, \"w\", newline=\"\",encoding=\"utf-8\") as f:#Creamos un archivo csv para guardar los resultados\n",
    "    wrt = csv.writer(f)\n",
    "    wrt.writerow([\"File\",\"ML algorithm\",\"accuracy\",\"Precision\", \"Recall\" , \"F1-score\",\"Time\"])\n",
    "\n",
    "#Este bucle itera sobre la lista de ataques, ejecutando para cada uno todos los algoritmos de ML\n",
    "for j in csv_files: #this loop runs on the list containing the filenames.Operations are repeated for all attack files\n",
    "    print ('%-17s %-17s  %-15s %-15s %-15s %-15s %-15s' % (\"File\",\"ML algorithm\",\"accuracy\",\"Precision\", \"Recall\" , \"F1-score\",\"Time\"))# print output header   \n",
    "    feature_list=list(features[j[0:-4]])\n",
    "    df=pd.read_csv(path+j,usecols=feature_list)#read an attack file.\n",
    "    df=df.fillna(0)\n",
    "    attack_or_not=[]\n",
    "    for i in df[\"Label\"]: #it changes the normal label to \"1\" and the attack tag to \"0\" for use in the machine learning algorithm\n",
    "        \n",
    "        if i ==\"BENIGN\":\n",
    "            attack_or_not.append(1)\n",
    "        else:\n",
    "            attack_or_not.append(0)           \n",
    "    df[\"Label\"]=attack_or_not\n",
    "\n",
    "    \n",
    "    y = df[\"Label\"] #this section separates the label and the data into two separate pieces, as Label=y Data=X \n",
    "    del df[\"Label\"]\n",
    "    feature_list.remove('Label')\n",
    "    X = df[feature_list]\n",
    "\n",
    "    \n",
    "    for ii in ml_list: #this loop runs on the list containing the machine learning algorithm names. Operations are repeated for all the 7 algorithm\n",
    "        precision=[]\n",
    "        recall=[]\n",
    "        f1=[]\n",
    "        accuracy=[]\n",
    "        t_time=[]\n",
    "        for i in range(repetition): # This loop allows cross-validation and machine learning algorithm to be repeated 10 times\n",
    "            second=time.time()#time stamp for processing time\n",
    "\n",
    "            # cross-validation\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y,#  data (X) and labels (y) are divided into 2 parts to be sent to the machine learning algorithm (80% train,%20 test). \n",
    "                test_size = 0.20, random_state = repetition)#  So, in total there are 4 tracks: training data(X_train), training tag (y_train), test data(X_test) and test tag(y_test).\n",
    "\n",
    "\n",
    "            #machine learning algorithm is applied in this section\n",
    "            clf = ml_list[ii]#choose algorithm from ml_list dictionary                                                                          \n",
    "            clf.fit(X_train, y_train)\n",
    "            predict =clf.predict(X_test)\n",
    "        \n",
    "            #makes \"classification report\" and assigns the precision, f-measure, and recall values.s.    \n",
    "\n",
    "\n",
    "            f_1=f1_score(y_test, predict, average='macro')\n",
    "            pr=precision_score(y_test, predict, average='macro')\n",
    "            rc=recall_score(y_test, predict, average='macro')\n",
    "\n",
    "\n",
    "            precision.append(float(pr))\n",
    "            recall.append(float(rc))\n",
    "            f1.append(float(f_1))\n",
    "            accuracy.append(clf.score(X_test, y_test))\n",
    "            t_time.append(float((time.time()-second)) )\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "        print ('%-17s %-17s  %-15s %-15s %-15s %-15s %-15s' % (j[0:-4],ii,str(round(np.mean(accuracy),2)),str(round(np.mean(precision),2)), \n",
    "            str(round(np.mean(recall),2)),str(round(np.mean(f1),2)),str(round(np.mean(t_time),4))))#the result of the ten repetitions is printed on the screen.\n",
    "\n",
    "        with open(result, \"a\", newline=\"\",encoding=\"utf-8\") as f: # all the values found are saved in the opened file.\n",
    "            wrt = csv.writer(f)\n",
    "            for i in range(0,len(t_time)):\n",
    "                wrt.writerow([j[0:-4],ii,accuracy[i],precision[i],recall[i],f1[i],t_time[i]])#file name, algorithm name, precision, recall and f-measure are writed in CSV file\n",
    "   \n",
    "     # In this section, Box graphics are created for the results of machine learning algorithms and saved in the feaure_graph folder.\n",
    "     #   plt.boxplot(f1)\n",
    "     #   plt.title(\"All Dataset - \" +str(ii))\n",
    "     #   plt.ylabel('F-measure')\n",
    "     #   plt.savefig(folder_name+j[0:-4]+str(ii)+\".pdf\",bbox_inches='tight', papertype = 'a4', orientation = 'portrait', format = 'pdf')\n",
    "     #   plt.show()# you can remove the # sign if you want to see the graphics simultaneously\n",
    "\n",
    "print(\"Cálculo completado\")\n",
    "print(\"Tiempo total de ejecución: = \",time.time()- seconds ,\"segundos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File              ML algorithm       accuracy        Precision       Recall          F1-score        Time           \n",
      "all_data_preproc  Gradient Boosting Classifier  0.94            0.97            0.74            0.81            4.1431         \n",
      "Cálculo completado\n",
      "Tiempo total de ejecución: =  11.26466989517212 segundos\n"
     ]
    }
   ],
   "source": [
    "####  ALL_DATA: 7 LABELS - P2 ALGORITHMS\n",
    "\n",
    "#  Se requiere el archivo all_data_preproc.csv para la ejecución de este código.\n",
    "#  El archivo all_data_preproc.csv debe estar ubicado en el mismo directorio que el programa.\n",
    "\n",
    "#   El objetivo de este código es aplicar algoritmos de aprendizaje automático al dataset y observar su desempeño\n",
    "#   Los algoritmos usados son: Naive Bayes, QDA, Random Forest, ID3, AdaBoost, MLP y K Nearest Neighbors\n",
    "#   Las medidas de rendimiento calculadas y mostradas son accuracy, precision, recall y F1-score. También se recoge para cada uno el tiempo que ha tardado en calcular.\n",
    "#   Se creará también un archivo CSV (results_1.csv) con los resultados y un directorio (result_graph) con los correspondientes gráficos\n",
    "\n",
    "##  the some codes parts used for calculation and graphing are taken from the following site.\n",
    "##  http://scikit-learn.org\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression #Logistic Regression\n",
    "from sklearn.svm import SVC #Support Vector Machine\n",
    "from sklearn.naive_bayes import MultinomialNB #Naive Bayes Multinomial\n",
    "from sklearn.linear_model import SGDClassifier #Stochastic Gradient Descent Classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier #Gradient Boosting Classifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "import warnings\n",
    "import math\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "result=\"./results/results_2.csv\" #a CSV file is named in which the results are saved.\n",
    "csv_files=[\"all_data_preproc.csv\"]# CSV files names: #The names of the dataset files (csv_files).\n",
    "path=\"\"\n",
    "repetition=1\n",
    "\n",
    "\n",
    "def folder(f_name):\n",
    "    try:\n",
    "        if not os.path.exists(f_name):\n",
    "            os.makedirs(f_name)\n",
    "    except OSError:\n",
    "        print (\"The folder could not be created!\")\n",
    "\n",
    "folder_name=\"./results/\"\n",
    "folder(folder_name)\n",
    "folder_name=\"./results/result_graph_1/\"\n",
    "folder(folder_name)\n",
    "\n",
    "\n",
    "#   Los algoritmos utilizados se manejarán con una diccionario:\n",
    "ml_list={\n",
    "#\"Logistic Regression\":LogisticRegression(penalty='l2', dual=False, solver='newton-cg', class_weight='balanced'),\n",
    "#\"Support Vector Machine\":SVC(gamma='auto', kernel='linear', C=5),\n",
    "#\"Naive Bayes Multinomial\":MultinomialNB(alpha=0.0, fit_prior=False),\n",
    "#\"SGD Classifier\" :SGDClassifier(max_iter=2000, tol=1e-4, loss='squared_hinge', penalty='l1'),\n",
    "\"Gradient Boosting Classifier\":GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "}\n",
    "\n",
    "\n",
    "features={  'all_data_preproc': [\"dsport\", \"sbytes\", \"sport\", \"Sload\", \"dbytes\", \"Spkts\", \"dstip\", \"Label\"]}\n",
    "\n",
    "seconds=time.time() #Para calcular el tiempo de cálculo\n",
    "\n",
    "\n",
    "with open(result, \"w\", newline=\"\",encoding=\"utf-8\") as f:#Creamos un archivo csv para guardar los resultados\n",
    "    wrt = csv.writer(f)\n",
    "    wrt.writerow([\"File\",\"ML algorithm\",\"accuracy\",\"Precision\", \"Recall\" , \"F1-score\",\"Time\"])\n",
    "\n",
    "#Este bucle itera sobre la lista de ataques, ejecutando para cada uno todos los algoritmos de ML\n",
    "for j in csv_files: #this loop runs on the list containing the filenames.Operations are repeated for all attack files\n",
    "    print ('%-17s %-17s  %-15s %-15s %-15s %-15s %-15s' % (\"File\",\"ML algorithm\",\"accuracy\",\"Precision\", \"Recall\" , \"F1-score\",\"Time\"))# print output header   \n",
    "    feature_list=list(features[j[0:-4]])\n",
    "    df=pd.read_csv(path+j,usecols=feature_list)#read an attack file.\n",
    "    df=df.fillna(0)\n",
    "    df = df.sample(100000)\n",
    "    attack_or_not=[]\n",
    "    for i in df[\"Label\"]: #it changes the normal label to \"1\" and the attack tag to \"0\" for use in the machine learning algorithm\n",
    "        \n",
    "        if i ==\"BENIGN\":\n",
    "            attack_or_not.append(1)\n",
    "        else:\n",
    "            attack_or_not.append(0)           \n",
    "    df[\"Label\"]=attack_or_not\n",
    "\n",
    "    \n",
    "    y = df[\"Label\"] #this section separates the label and the data into two separate pieces, as Label=y Data=X \n",
    "    del df[\"Label\"]\n",
    "    feature_list.remove('Label')\n",
    "    X = df[feature_list]\n",
    "\n",
    "    \n",
    "    for ii in ml_list: #this loop runs on the list containing the machine learning algorithm names. Operations are repeated for all the 7 algorithm\n",
    "        precision=[]\n",
    "        recall=[]\n",
    "        f1=[]\n",
    "        accuracy=[]\n",
    "        t_time=[]\n",
    "        for i in range(repetition):\n",
    "            second=time.time()\n",
    "\n",
    "            if ii in [\"Naive Bayes Multinomial\", \"SGD Classifier\", \"Logistic Regression\"]:\n",
    "                scaler = MinMaxScaler()\n",
    "                X = scaler.fit_transform(X)\n",
    "            if ii in [\"Support Vector Machine\"]:\n",
    "                scaler = StandardScaler()\n",
    "                X = scaler.fit_transform(X)\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y,#  data (X) and labels (y) are divided into 2 parts to be sent to the machine learning algorithm (80% train,%20 test). \n",
    "                test_size = 0.20, random_state = repetition)#  So, in total there are 4 tracks: training data(X_train), training tag (y_train), test data(X_test) and test tag(y_test).\n",
    "\n",
    "            #machine learning algorithm is applied in this section\n",
    "            clf = ml_list[ii]#choose algorithm from ml_list dictionary                                                                          \n",
    "            clf.fit(X_train, y_train)\n",
    "            predict =clf.predict(X_test)\n",
    "        \n",
    "            #makes \"classification report\" and assigns the precision, f-measure, and recall values.s.    \n",
    "\n",
    "            f_1=f1_score(y_test, predict, average='macro')\n",
    "            pr=precision_score(y_test, predict, average='macro')\n",
    "            rc=recall_score(y_test, predict, average='macro')\n",
    "\n",
    "\n",
    "            precision.append(float(pr))\n",
    "            recall.append(float(rc))\n",
    "            f1.append(float(f_1))\n",
    "            accuracy.append(clf.score(X_test, y_test))\n",
    "            t_time.append(float((time.time()-second)) )\n",
    "\n",
    "            \n",
    "        print ('%-17s %-17s  %-15s %-15s %-15s %-15s %-15s' % (j[0:-4],ii,str(round(np.mean(accuracy),2)),str(round(np.mean(precision),2)), \n",
    "            str(round(np.mean(recall),2)),str(round(np.mean(f1),2)),str(round(np.mean(t_time),4))))#the result of the ten repetitions is printed on the screen.\n",
    "\n",
    "        with open(result, \"a\", newline=\"\",encoding=\"utf-8\") as f: # all the values found are saved in the opened file.\n",
    "            wrt = csv.writer(f)\n",
    "            for i in range(0,len(t_time)):\n",
    "                wrt.writerow([j[0:-4],ii,accuracy[i],precision[i],recall[i],f1[i],t_time[i]])#file name, algorithm name, precision, recall and f-measure are writed in CSV file\n",
    "   \n",
    "     # In this section, Box graphics are created for the results of machine learning algorithms and saved in the feaure_graph folder.\n",
    "     #   plt.boxplot(f1)\n",
    "     #   plt.title(\"All Dataset - \" +str(ii))\n",
    "     #   plt.ylabel('F-measure')\n",
    "     #   plt.savefig(folder_name+j[0:-4]+str(ii)+\".pdf\",bbox_inches='tight', papertype = 'a4', orientation = 'portrait', format = 'pdf')\n",
    "     #   plt.show()# you can remove the # sign if you want to see the graphics simultaneously\n",
    "\n",
    "print(\"Cálculo completado\")\n",
    "print(\"Tiempo total de ejecución: = \",time.time()- seconds ,\"segundos\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File              ML algorithm       accuracy        Precision       Recall          F1-score        Time           \n",
      "all_data_preproc  Nearest Neighbors  0.99            0.98            0.97            0.97            268.961        \n",
      "Cálculo completado\n",
      "Tiempo total de ejecución: =  820.0980660915375 segundos\n"
     ]
    }
   ],
   "source": [
    "####  ALL_DATA: 12 LABELS - P1 ALGORITHMS\n",
    "\n",
    "#  Se requiere el archivo all_data_preproc.csv para la ejecución de este código.\n",
    "#  El archivo all_data_preproc.csv debe estar ubicado en el mismo directorio que el programa.\n",
    "\n",
    "#   El objetivo de este código es aplicar algoritmos de aprendizaje automático al dataset y observar su desempeño\n",
    "#   Los algoritmos usados son: Naive Bayes, QDA, Random Forest, ID3, AdaBoost, MLP y K Nearest Neighbors\n",
    "#   Las medidas de rendimiento calculadas y mostradas son accuracy, precision, recall y F1-score. También se recoge para cada uno el tiempo que ha tardado en calcular.\n",
    "#   Se creará también un archivo CSV (results_1.csv) con los resultados y un directorio (result_graph) con los correspondientes gráficos\n",
    "\n",
    "##  the some codes parts used for calculation and graphing are taken from the following site.\n",
    "##  http://scikit-learn.org\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "import warnings\n",
    "import math\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "result=\"./results/results_2.csv\" #a CSV file is named in which the results are saved.\n",
    "csv_files=[\"all_data_preproc.csv\"]# CSV files names: #The names of the dataset files (csv_files).\n",
    "path=\"\"\n",
    "repetition=10\n",
    "\n",
    "\n",
    "def folder(f_name):\n",
    "    try:\n",
    "        if not os.path.exists(f_name):\n",
    "            os.makedirs(f_name)\n",
    "    except OSError:\n",
    "        print (\"The folder could not be created!\")\n",
    "\n",
    "folder_name=\"./results/\"\n",
    "folder(folder_name)\n",
    "folder_name=\"./results/result_graph_1/\"\n",
    "folder(folder_name)\n",
    "\n",
    "\n",
    "#   Los algoritmos utilizados se manejarán con una diccionario:\n",
    "ml_list={\n",
    "#\"Naive Bayes\":GaussianNB(),\n",
    "#\"QDA\":QDA(),\n",
    "#\"Random Forest\":RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "#\"ID3\" :DecisionTreeClassifier(max_depth=5,criterion=\"entropy\"),\n",
    "#\"AdaBoost\":AdaBoostClassifier(),\n",
    "#\"MLP\":MLPClassifier(hidden_layer_sizes=(13,13,13),max_iter=500),\n",
    "\"Nearest Neighbors\":KNeighborsClassifier(3)\n",
    "}\n",
    "\n",
    "features={ 'all_data_preproc': [\"service\",\"dbytes\",\"dsport\",\"Sload\",\"sttl\",\"sbytes\",\"sloss\",\"sport\",\"proto\",\"Dpkts\",\"dstip\",\"Dload\", \"Label\"]}\n",
    "\n",
    "\n",
    "seconds=time.time() #Para calcular el tiempo de cálculo\n",
    "\n",
    "\n",
    "with open(result, \"w\", newline=\"\",encoding=\"utf-8\") as f:#Creamos un archivo csv para guardar los resultados\n",
    "    wrt = csv.writer(f)\n",
    "    wrt.writerow([\"File\",\"ML algorithm\",\"accuracy\",\"Precision\", \"Recall\" , \"F1-score\",\"Time\"])\n",
    "\n",
    "#Este bucle itera sobre la lista de ataques, ejecutando para cada uno todos los algoritmos de ML\n",
    "for j in csv_files: #this loop runs on the list containing the filenames.Operations are repeated for all attack files\n",
    "    print ('%-17s %-17s  %-15s %-15s %-15s %-15s %-15s' % (\"File\",\"ML algorithm\",\"accuracy\",\"Precision\", \"Recall\" , \"F1-score\",\"Time\"))# print output header   \n",
    "    feature_list=list(features[j[0:-4]])\n",
    "    df=pd.read_csv(path+j,usecols=feature_list)#read an attack file.\n",
    "    df=df.fillna(0)\n",
    "    attack_or_not=[]\n",
    "    for i in df[\"Label\"]: #it changes the normal label to \"1\" and the attack tag to \"0\" for use in the machine learning algorithm\n",
    "        \n",
    "        if i ==\"BENIGN\":\n",
    "            attack_or_not.append(1)\n",
    "        else:\n",
    "            attack_or_not.append(0)           \n",
    "    df[\"Label\"]=attack_or_not\n",
    "\n",
    "    \n",
    "    y = df[\"Label\"] #this section separates the label and the data into two separate pieces, as Label=y Data=X \n",
    "    del df[\"Label\"]\n",
    "    feature_list.remove('Label')\n",
    "    X = df[feature_list]\n",
    "\n",
    "    \n",
    "    for ii in ml_list: #this loop runs on the list containing the machine learning algorithm names. Operations are repeated for all the 7 algorithm\n",
    "        precision=[]\n",
    "        recall=[]\n",
    "        f1=[]\n",
    "        accuracy=[]\n",
    "        t_time=[]\n",
    "        for i in range(repetition): # This loop allows cross-validation and machine learning algorithm to be repeated 10 times\n",
    "            second=time.time()#time stamp for processing time\n",
    "\n",
    "            # cross-validation\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y,#  data (X) and labels (y) are divided into 2 parts to be sent to the machine learning algorithm (80% train,%20 test). \n",
    "                test_size = 0.20, random_state = repetition)#  So, in total there are 4 tracks: training data(X_train), training tag (y_train), test data(X_test) and test tag(y_test).\n",
    "\n",
    "\n",
    "            #machine learning algorithm is applied in this section\n",
    "            clf = ml_list[ii]#choose algorithm from ml_list dictionary                                                                          \n",
    "            clf.fit(X_train, y_train)\n",
    "            predict =clf.predict(X_test)\n",
    "        \n",
    "            #makes \"classification report\" and assigns the precision, f-measure, and recall values.s.    \n",
    "\n",
    "\n",
    "            f_1=f1_score(y_test, predict, average='macro')\n",
    "            pr=precision_score(y_test, predict, average='macro')\n",
    "            rc=recall_score(y_test, predict, average='macro')\n",
    "\n",
    "\n",
    "            precision.append(float(pr))\n",
    "            recall.append(float(rc))\n",
    "            f1.append(float(f_1))\n",
    "            accuracy.append(clf.score(X_test, y_test))\n",
    "            t_time.append(float((time.time()-second)) )\n",
    "\n",
    "            \n",
    "        print ('%-17s %-17s  %-15s %-15s %-15s %-15s %-15s' % (j[0:-4],ii,str(round(np.mean(accuracy),2)),str(round(np.mean(precision),2)), \n",
    "            str(round(np.mean(recall),2)),str(round(np.mean(f1),2)),str(round(np.mean(t_time),4))))#the result of the ten repetitions is printed on the screen.\n",
    "\n",
    "        with open(result, \"a\", newline=\"\",encoding=\"utf-8\") as f: # all the values found are saved in the opened file.\n",
    "            wrt = csv.writer(f)\n",
    "            for i in range(0,len(t_time)):\n",
    "                wrt.writerow([j[0:-4],ii,accuracy[i],precision[i],recall[i],f1[i],t_time[i]])#file name, algorithm name, precision, recall and f-measure are writed in CSV file\n",
    "   \n",
    "     # In this section, Box graphics are created for the results of machine learning algorithms and saved in the feaure_graph folder.\n",
    "     #   plt.boxplot(f1)\n",
    "     #   plt.title(\"All Dataset - \" +str(ii))\n",
    "     #   plt.ylabel('F-measure')\n",
    "     #   plt.savefig(folder_name+j[0:-4]+str(ii)+\".pdf\",bbox_inches='tight', papertype = 'a4', orientation = 'portrait', format = 'pdf')\n",
    "     #   plt.show()# you can remove the # sign if you want to see the graphics simultaneously\n",
    "\n",
    "print(\"Cálculo completado\")\n",
    "print(\"Tiempo total de ejecución: = \",time.time()- seconds ,\"segundos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File              ML algorithm       accuracy        Precision       Recall          F1-score        Time           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_data_preproc  Gradient Boosting Classifier  0.97            0.92            0.98            0.95            12.9346        \n",
      "Cálculo completado\n",
      "Tiempo total de ejecución: =  21.877104997634888 segundos\n"
     ]
    }
   ],
   "source": [
    "####  ALL_DATA: 12 LABELS - P2 ALGORITHMS\n",
    "\n",
    "#  Se requiere el archivo all_data_preproc.csv para la ejecución de este código.\n",
    "#  El archivo all_data_preproc.csv debe estar ubicado en el mismo directorio que el programa.\n",
    "\n",
    "#   El objetivo de este código es aplicar algoritmos de aprendizaje automático al dataset y observar su desempeño\n",
    "#   Los algoritmos usados son: Naive Bayes, QDA, Random Forest, ID3, AdaBoost, MLP y K Nearest Neighbors\n",
    "#   Las medidas de rendimiento calculadas y mostradas son accuracy, precision, recall y F1-score. También se recoge para cada uno el tiempo que ha tardado en calcular.\n",
    "#   Se creará también un archivo CSV (results_1.csv) con los resultados y un directorio (result_graph) con los correspondientes gráficos\n",
    "\n",
    "##  the some codes parts used for calculation and graphing are taken from the following site.\n",
    "##  http://scikit-learn.org\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression #Logistic Regression\n",
    "from sklearn.svm import SVC #Support Vector Machine\n",
    "from sklearn.naive_bayes import MultinomialNB #Naive Bayes Multinomial\n",
    "from sklearn.linear_model import SGDClassifier #Stochastic Gradient Descent Classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier #Gradient Boosting Classifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "import warnings\n",
    "import math\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "result=\"./results/results_2.csv\" #a CSV file is named in which the results are saved.\n",
    "csv_files=[\"all_data_preproc.csv\"]# CSV files names: #The names of the dataset files (csv_files).\n",
    "path=\"\"\n",
    "repetition=1\n",
    "\n",
    "\n",
    "def folder(f_name):\n",
    "    try:\n",
    "        if not os.path.exists(f_name):\n",
    "            os.makedirs(f_name)\n",
    "    except OSError:\n",
    "        print (\"The folder could not be created!\")\n",
    "\n",
    "folder_name=\"./results/\"\n",
    "folder(folder_name)\n",
    "folder_name=\"./results/result_graph_1/\"\n",
    "folder(folder_name)\n",
    "\n",
    "\n",
    "#   Los algoritmos utilizados se manejarán con una diccionario:\n",
    "ml_list={\n",
    "#\"Logistic Regression\":LogisticRegression(penalty='l2', dual=False, solver='newton-cg', class_weight='balanced'),\n",
    "#\"Support Vector Machine\":SVC(gamma='auto', kernel='linear', C=5),\n",
    "#\"Naive Bayes Multinomial\":MultinomialNB(alpha=0.0, fit_prior=False),\n",
    "#\"SGD Classifier\" :SGDClassifier(max_iter=2000, tol=1e-4, loss='squared_hinge', penalty='l1'),\n",
    "\"Gradient Boosting Classifier\":GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "}\n",
    "\n",
    "\n",
    "features={ 'all_data_preproc': [\"service\",\"dbytes\",\"dsport\",\"Sload\",\"sttl\",\"sbytes\",\"sloss\",\"sport\",\"proto\",\"Dpkts\",\"dstip\",\"Dload\", \"Label\"]}\n",
    "\n",
    "seconds=time.time() #Para calcular el tiempo de cálculo\n",
    "\n",
    "\n",
    "with open(result, \"w\", newline=\"\",encoding=\"utf-8\") as f:#Creamos un archivo csv para guardar los resultados\n",
    "    wrt = csv.writer(f)\n",
    "    wrt.writerow([\"File\",\"ML algorithm\",\"accuracy\",\"Precision\", \"Recall\" , \"F1-score\",\"Time\"])\n",
    "\n",
    "#Este bucle itera sobre la lista de ataques, ejecutando para cada uno todos los algoritmos de ML\n",
    "for j in csv_files: #this loop runs on the list containing the filenames.Operations are repeated for all attack files\n",
    "    print ('%-17s %-17s  %-15s %-15s %-15s %-15s %-15s' % (\"File\",\"ML algorithm\",\"accuracy\",\"Precision\", \"Recall\" , \"F1-score\",\"Time\"))# print output header   \n",
    "    feature_list=list(features[j[0:-4]])\n",
    "    df=pd.read_csv(path+j,usecols=feature_list)#read an attack file.\n",
    "    df=df.fillna(0)\n",
    "    df=df.sample(100000)\n",
    "    attack_or_not=[]\n",
    "    for i in df[\"Label\"]: #it changes the normal label to \"1\" and the attack tag to \"0\" for use in the machine learning algorithm\n",
    "        \n",
    "        if i ==\"BENIGN\":\n",
    "            attack_or_not.append(1)\n",
    "        else:\n",
    "            attack_or_not.append(0)           \n",
    "    df[\"Label\"]=attack_or_not\n",
    "\n",
    "    \n",
    "    y = df[\"Label\"] #this section separates the label and the data into two separate pieces, as Label=y Data=X \n",
    "    del df[\"Label\"]\n",
    "    feature_list.remove('Label')\n",
    "    X = df[feature_list]\n",
    "\n",
    "    \n",
    "    for ii in ml_list: #this loop runs on the list containing the machine learning algorithm names. Operations are repeated for all the 7 algorithm\n",
    "        precision=[]\n",
    "        recall=[]\n",
    "        f1=[]\n",
    "        accuracy=[]\n",
    "        t_time=[]\n",
    "        for i in range(repetition):\n",
    "            second=time.time()\n",
    "\n",
    "            if ii in [\"Naive Bayes Multinomial\", \"SGD Classifier\", \"Logistic Regression\"]:\n",
    "                scaler = MinMaxScaler()\n",
    "                X = scaler.fit_transform(X)\n",
    "            if ii in [\"Support Vector Machine\"]:\n",
    "                scaler = StandardScaler()\n",
    "                X = scaler.fit_transform(X)\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y,#  data (X) and labels (y) are divided into 2 parts to be sent to the machine learning algorithm (80% train,%20 test). \n",
    "                test_size = 0.20, random_state = repetition)#  So, in total there are 4 tracks: training data(X_train), training tag (y_train), test data(X_test) and test tag(y_test).\n",
    "\n",
    "            #machine learning algorithm is applied in this section\n",
    "            clf = ml_list[ii]#choose algorithm from ml_list dictionary                                                                          \n",
    "            clf.fit(X_train, y_train)\n",
    "            predict =clf.predict(X_test)\n",
    "        \n",
    "            #makes \"classification report\" and assigns the precision, f-measure, and recall values.s.    \n",
    "\n",
    "            f_1=f1_score(y_test, predict, average='macro')\n",
    "            pr=precision_score(y_test, predict, average='macro')\n",
    "            rc=recall_score(y_test, predict, average='macro')\n",
    "\n",
    "\n",
    "            precision.append(float(pr))\n",
    "            recall.append(float(rc))\n",
    "            f1.append(float(f_1))\n",
    "            accuracy.append(clf.score(X_test, y_test))\n",
    "            t_time.append(float((time.time()-second)) )\n",
    "\n",
    "            \n",
    "        print ('%-17s %-17s  %-15s %-15s %-15s %-15s %-15s' % (j[0:-4],ii,str(round(np.mean(accuracy),2)),str(round(np.mean(precision),2)), \n",
    "            str(round(np.mean(recall),2)),str(round(np.mean(f1),2)),str(round(np.mean(t_time),4))))#the result of the ten repetitions is printed on the screen.\n",
    "\n",
    "        with open(result, \"a\", newline=\"\",encoding=\"utf-8\") as f: # all the values found are saved in the opened file.\n",
    "            wrt = csv.writer(f)\n",
    "            for i in range(0,len(t_time)):\n",
    "                wrt.writerow([j[0:-4],ii,accuracy[i],precision[i],recall[i],f1[i],t_time[i]])#file name, algorithm name, precision, recall and f-measure are writed in CSV file\n",
    "   \n",
    "     # In this section, Box graphics are created for the results of machine learning algorithms and saved in the feaure_graph folder.\n",
    "     #   plt.boxplot(f1)\n",
    "     #   plt.title(\"All Dataset - \" +str(ii))\n",
    "     #   plt.ylabel('F-measure')\n",
    "     #   plt.savefig(folder_name+j[0:-4]+str(ii)+\".pdf\",bbox_inches='tight', papertype = 'a4', orientation = 'portrait', format = 'pdf')\n",
    "     #   plt.show()# you can remove the # sign if you want to see the graphics simultaneously\n",
    "\n",
    "print(\"Cálculo completado\")\n",
    "print(\"Tiempo total de ejecución: = \",time.time()- seconds ,\"segundos\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
