{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNSW-NB15\n",
    "Implementaci√≥n de los IDS separadamente para cada ataque usando algoritmos de aprendizaje supervisado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File              ML algorithm       accuracy        Precision       Recall          F1-score        Time           \n",
      "Analysis          Naive Bayes        0.85            0.83            0.83            0.83            0.0153         \n",
      "Analysis          QDA                0.99            0.98            0.98            0.98            0.0171         \n",
      "Analysis          Random Forest      1.0             1.0             1.0             1.0             0.0316         \n",
      "Analysis          ID3                1.0             1.0             0.99            0.99            0.0116         \n",
      "Analysis          AdaBoost           1.0             1.0             1.0             1.0             0.1863         \n",
      "Analysis          MLP                0.94            0.95            0.93            0.93            0.7534         \n",
      "Analysis          Nearest Neighbors  0.99            0.99            0.99            0.99            0.27           \n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "File              ML algorithm       accuracy        Precision       Recall          F1-score        Time           \n",
      "Backdoor          Naive Bayes        0.69            0.56            0.53            0.5             0.0133         \n",
      "Backdoor          QDA                0.97            0.96            0.97            0.96            0.0127         \n",
      "Backdoor          Random Forest      0.99            0.98            0.99            0.98            0.0337         \n",
      "Backdoor          ID3                0.99            0.98            0.99            0.99            0.0134         \n",
      "Backdoor          AdaBoost           0.98            0.98            0.99            0.98            0.2047         \n",
      "Backdoor          MLP                0.71            0.74            0.63            0.57            0.543          \n",
      "Backdoor          Nearest Neighbors  0.96            0.94            0.95            0.95            0.133          \n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "File              ML algorithm       accuracy        Precision       Recall          F1-score        Time           \n",
      "DoS               Naive Bayes        0.94            0.93            0.93            0.93            0.0348         \n",
      "DoS               QDA                0.94            0.93            0.93            0.93            0.032          \n",
      "DoS               Random Forest      0.99            0.98            0.99            0.99            0.1134         \n",
      "DoS               ID3                0.99            0.98            0.99            0.99            0.0373         \n",
      "DoS               AdaBoost           0.99            0.98            0.99            0.99            0.8045         \n",
      "DoS               MLP                0.94            0.93            0.93            0.93            5.9237         \n",
      "DoS               Nearest Neighbors  0.99            0.99            0.99            0.99            1.6144         \n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "File              ML algorithm       accuracy        Precision       Recall          F1-score        Time           \n",
      "Exploits          Naive Bayes        0.85            0.85            0.79            0.81            0.0804         \n",
      "Exploits          QDA                0.88            0.9             0.81            0.84            0.0876         \n",
      "Exploits          Random Forest      0.99            0.98            0.99            0.98            0.3478         \n",
      "Exploits          ID3                0.99            0.99            0.98            0.99            0.108          \n",
      "Exploits          AdaBoost           0.99            0.98            0.99            0.99            2.7252         \n",
      "Exploits          MLP                0.96            0.96            0.95            0.96            13.7761        \n",
      "Exploits          Nearest Neighbors  0.99            0.99            0.99            0.99            5.2117         \n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "File              ML algorithm       accuracy        Precision       Recall          F1-score        Time           \n",
      "Fuzzers           Naive Bayes        0.7             0.35            0.5             0.41            0.0559         \n",
      "Fuzzers           QDA                0.99            0.98            0.99            0.99            0.0648         \n",
      "Fuzzers           Random Forest      0.99            0.98            0.99            0.99            0.231          \n",
      "Fuzzers           ID3                0.99            0.98            0.99            0.99            0.0841         \n",
      "Fuzzers           AdaBoost           0.99            0.98            0.99            0.99            1.6642         \n",
      "Fuzzers           MLP                0.65            0.77            0.67            0.61            4.0331         \n",
      "Fuzzers           Nearest Neighbors  0.77            0.72            0.7             0.71            1.9364         \n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "File              ML algorithm       accuracy        Precision       Recall          F1-score        Time           \n",
      "Generic           Naive Bayes        0.7             0.61            0.58            0.58            0.4574         \n",
      "Generic           QDA                0.65            0.72            0.75            0.65            0.5571         \n",
      "Generic           Random Forest      0.99            1.0             0.99            0.99            3.5781         \n",
      "Generic           ID3                0.99            1.0             0.99            0.99            1.0917         \n",
      "Generic           AdaBoost           0.99            1.0             0.99            0.99            22.6866        \n",
      "Generic           MLP                0.72            0.52            0.5             0.42            34.7862        \n",
      "Generic           Nearest Neighbors  1.0             1.0             0.99            1.0             82.5919        \n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "File              ML algorithm       accuracy        Precision       Recall          F1-score        Time           \n",
      "Reconnaissance    Naive Bayes        0.86            0.84            0.9             0.85            0.0273         \n",
      "Reconnaissance    QDA                0.99            0.98            0.99            0.99            0.0266         \n",
      "Reconnaissance    Random Forest      0.99            0.99            0.99            0.99            0.1104         \n",
      "Reconnaissance    ID3                1.0             0.99            1.0             0.99            0.0436         \n",
      "Reconnaissance    AdaBoost           0.99            0.99            0.99            0.99            0.793          \n",
      "Reconnaissance    MLP                0.98            0.98            0.98            0.98            2.0645         \n",
      "Reconnaissance    Nearest Neighbors  0.99            0.99            0.99            0.99            0.8713         \n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "File              ML algorithm       accuracy        Precision       Recall          F1-score        Time           \n",
      "Shellcode         Naive Bayes        1.0             0.99            1.0             1.0             0.0097         \n",
      "Shellcode         QDA                0.29            0.15            0.5             0.23            0.0089         \n",
      "Shellcode         Random Forest      1.0             1.0             1.0             1.0             0.0235         \n",
      "Shellcode         ID3                1.0             1.0             1.0             1.0             0.0091         \n",
      "Shellcode         AdaBoost           1.0             1.0             1.0             1.0             0.131          \n",
      "Shellcode         MLP                1.0             1.0             1.0             1.0             1.162          \n",
      "Shellcode         Nearest Neighbors  1.0             1.0             1.0             1.0             0.0808         \n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "File              ML algorithm       accuracy        Precision       Recall          F1-score        Time           \n",
      "Worms             Naive Bayes        0.71            0.35            0.5             0.42            0.0073         \n",
      "Worms             QDA                0.98            0.98            0.98            0.98            0.0075         \n",
      "Worms             Random Forest      0.99            0.99            0.99            0.99            0.0186         \n",
      "Worms             ID3                0.99            0.99            0.99            0.99            0.0073         \n",
      "Worms             AdaBoost           0.99            0.99            0.99            0.99            0.0782         \n",
      "Worms             MLP                0.59            0.63            0.54            0.45            0.1012         \n",
      "Worms             Nearest Neighbors  0.65            0.56            0.55            0.55            0.0174         \n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "C√°lculo completado\n",
      "Tiempo total de ejecuci√≥n: =  1929.2133095264435 segundos\n"
     ]
    }
   ],
   "source": [
    "#  Se requiere el archivo all_data.csv para la ejecuci√≥n de este c√≥digo.\n",
    "#  El archivo all_data.csv debe estar ubicado en el mismo directorio que el programa.\n",
    "\n",
    "#   El objetivo de este c√≥digo es aplicar algoritmos de aprendizaje autom√°tico al dataset y observar su desempe√±o\n",
    "#   Los algoritmos usados son: Naive Bayes, QDA, Random Forest, ID3, AdaBoost, MLP y K Nearest Neighbors\n",
    "#   Las medidas de rendimiento calculadas y mostradas son accuracy, precision, recall y F1-score. Tambi√©n se recoge para cada uno el tiempo que ha tardado en calcular.\n",
    "#   Se crear√° tambi√©n un archivo CSV (results_1.csv) con los resultados y un directorio (result_graph) con los correspondientes gr√°ficos\n",
    "\n",
    "##  the some codes parts used for calculation and graphing are taken from the following site.\n",
    "##  http://scikit-learn.org\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "import warnings\n",
    "import math\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "result=\"./results/results_1.csv\" #Los resultados se guardar√°n en este archivo\n",
    "csv_files=os.listdir(\"attacks\") # Asignamos a una lista los nombres de los ataques, a partir de los ficheros contenidos en el directorio \"attacks\"\n",
    "path=\".\\\\attacks\\\\\"\n",
    "repetition=10\n",
    "\n",
    "\n",
    "def folder(f_name):\n",
    "    try:\n",
    "        if not os.path.exists(f_name):\n",
    "            os.makedirs(f_name)\n",
    "    except OSError:\n",
    "        print (\"The folder could not be created!\")\n",
    "\n",
    "folder_name=\"./results/\"\n",
    "folder(folder_name)\n",
    "folder_name=\"./results/result_graph_1/\"\n",
    "folder(folder_name)\n",
    "\n",
    "\n",
    "#   Los algoritmos utilizados se manejar√°n con una diccionario:\n",
    "ml_list={\n",
    "\"Naive Bayes\":GaussianNB(),\n",
    "\"QDA\":QDA(),\n",
    "\"Random Forest\":RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "\"ID3\" :DecisionTreeClassifier(max_depth=5,criterion=\"entropy\"),\n",
    "\"AdaBoost\":AdaBoostClassifier(),\n",
    "\"MLP\":MLPClassifier(hidden_layer_sizes=(13,13,13),max_iter=500),\n",
    "\"Nearest Neighbors\":KNeighborsClassifier(3)}\n",
    "\n",
    "\n",
    "\n",
    "# Los par√°metros a tener en cuenta para cada ataque quedan definidos en el siguiente diccionario\n",
    "# Se usar√°n, para cada ataque, los 4 par√°metros con m√°s importancia. Estos datos pueden verse en el archivo importance_list_for_attack_files.csv\n",
    "features={  'Generic': [\"service\",\"dbytes\",\"dsport\",\"Sload\",'Label'], \n",
    "            'Exploits': [\"sttl\",\"dsport\",\"sbytes\",\"dbytes\", 'Label'],\n",
    "            'Fuzzers': [\"sttl\",\"sloss\",\"sport\",\"Sload\", 'Label'],\n",
    "            'DoS': [\"sttl\",\"dsport\",\"dbytes\",\"sbytes\", 'Label'],\n",
    "            'Reconnaissance': [\"sttl\",\"dsport\",\"proto\",\"Dpkts\",'Label'],\n",
    "            'Analysis': [\"sttl\",\"dsport\",\"dstip\",\"proto\", 'Label'],\n",
    "            'Backdoor': [\"sttl\",\"dsport\",\"dbytes\",\"Dload\", 'Label'],\n",
    "            'Shellcode': [\"sttl\",\"dsport\",\"sbytes\",\"dbytes\",'Label'],\n",
    "            'Worms': [\"sttl\",\"dsport\",\"sbytes\",\"sport\",'Label']}\n",
    "\n",
    "seconds=time.time() #Para calcular el tiempo de c√°lculo\n",
    "\n",
    "\n",
    "\n",
    "with open(result, \"w\", newline=\"\",encoding=\"utf-8\") as f:#Creamos un archivo csv para guardar los resultados\n",
    "    wrt = csv.writer(f)\n",
    "    wrt.writerow([\"File\",\"ML algorithm\",\"accuracy\",\"Precision\", \"Recall\" , \"F1-score\",\"Time\"])\n",
    "\n",
    "#Este bucle itera sobre la lista de ataques, ejecutando para cada uno todos los algoritmos de ML\n",
    "for j in csv_files: \n",
    "    print ('%-17s %-17s  %-15s %-15s %-15s %-15s %-15s' % (\"File\",\"ML algorithm\",\"accuracy\",\"Precision\", \"Recall\" , \"F1-score\",\"Time\"))\n",
    "    a=[]\n",
    "    \n",
    "    feature_list=list(features[j[0:-4]])\n",
    "    df=pd.read_csv(path+j,usecols=feature_list)#read an attack file.\n",
    "    df=df.fillna(0)\n",
    "    attack_or_not=[]\n",
    "    for i in df['Label']: #Cambia la etiqueta normal por \"1\" y la de ataque por \"0\".\n",
    "        \n",
    "        if i ==\"BENIGN\":\n",
    "            attack_or_not.append(1)\n",
    "        else:\n",
    "            attack_or_not.append(0)           \n",
    "    df[\"Label\"]=attack_or_not\n",
    "\n",
    "    \n",
    "    y = df[\"Label\"] #Se separan las etiquetas de los datos, Label=y Data=X \n",
    "    del df[\"Label\"]\n",
    "    feature_list.remove('Label')\n",
    "    X = df[feature_list]\n",
    "\n",
    "    \n",
    "    for ii in ml_list: #El bucle itera sobre la lista de algoritmos a aplicar\n",
    "        precision=[]\n",
    "        recall=[]\n",
    "        f1=[]\n",
    "        accuracy=[]\n",
    "        t_time=[]\n",
    "        for i in range(repetition): # Se repite el algoritmo 10 veces para hacer validaci√≥n cruzada\n",
    "            second=time.time()#Para recoger el dato de tiempo\n",
    "\n",
    "            # Validaci√≥n cruzada:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y,#  data (X) and labels (y) are divided into 2 parts to be sent to the machine learning algorithm (80% train,%20 test). \n",
    "                test_size = 0.20, random_state = repetition)#  So, in total there are 4 tracks: training data(X_train), training tag (y_train), test data(X_test) and test tag(y_test).\n",
    "\n",
    "\n",
    "            #Aplicamos el algoritmo de ML:\n",
    "            clf = ml_list[ii] #Escogemos el algoritmo concreto                                                                         \n",
    "            clf.fit(X_train, y_train)\n",
    "            predict =clf.predict(X_test)\n",
    "        \n",
    "            #Se obtienen los datos de rendimiento tras la ejecuci√≥n:  \n",
    "            f_1=f1_score(y_test, predict, average='macro')\n",
    "            pr=precision_score(y_test, predict, average='macro')\n",
    "            rc=recall_score(y_test, predict, average='macro')\n",
    "\n",
    "            \n",
    "            precision.append(float(pr))\n",
    "            recall.append(float(rc))\n",
    "            f1.append(float(f_1))\n",
    "            accuracy.append(clf.score(X_test, y_test))\n",
    "            t_time.append(float((time.time()-second)))\n",
    "\n",
    "\n",
    "            \n",
    "        print ('%-17s %-17s  %-15s %-15s %-15s %-15s %-15s' % (j[0:-4],ii,str(round(np.mean(accuracy),2)),str(round(np.mean(precision),2)), \n",
    "            str(round(np.mean(recall),2)),str(round(np.mean(f1),2)),str(round(np.mean(t_time),4))))#the result of the ten repetitions is printed on the screen.\n",
    "\n",
    "        with open(result, \"a\", newline=\"\",encoding=\"utf-8\") as f: # all the values found are saved in the opened file.\n",
    "            wrt = csv.writer(f)\n",
    "            for i in range(0,len(t_time)):\n",
    "                wrt.writerow([j[0:-4],ii,accuracy[i],precision[i],recall[i],f1[i],t_time[i]])#file name, algorithm name, precision, recall and f-measure are writed in CSV file\n",
    "        a.append(f1)\n",
    "\n",
    "\n",
    "    #   Se generan gr√°ficos de caja y bigotes, y se guardan en el directorio result_graph_1:\n",
    "        \n",
    "    #ml=[\"Naive Bayes\",\"QDA\",\"Random Forest\",\"ID3\",\"AdaBoost\",\"MLP\",\"Nearest Neighbors\"]\n",
    "    #temp=0\n",
    "    #fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(12, 6), sharey=True)\n",
    "    #for c in range(2):\n",
    "    #    for b in range(4):\n",
    "    #        axes[c, b].boxplot(a[temp] )\n",
    "    #        axes[c, b].set_title(str(j[0:-4])+\" - \"+str(ml[temp]),fontsize=7)\n",
    "    #        axes[c, b].set_ylabel((\"F measure\"))\n",
    "    #        temp+=1\n",
    "    #        if temp==7:\n",
    "    #            break\n",
    "    #    if temp==7:\n",
    "    #        break\n",
    "    #plt.savefig(folder_name+j[0:-4]+\".pdf\",bbox_inches='tight', papertype = 'a4', orientation = 'portrait', format = 'pdf')\n",
    "    #plt.show()\n",
    "    print(\"\\n------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "    \n",
    "print(\"C√°lculo completado\")\n",
    "print(\"Tiempo total de ejecuci√≥n: = \",time.time()- seconds ,\"segundos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File              ML algorithm                 accuracy        Precision       Recall          F1-score        Time           \n",
      "Exploits          Logistic Regression          0.96            0.96            0.95            0.95            0.1152         \n",
      "Exploits          Support Vector Machine       0.87            0.89            0.79            0.82            58.2061        \n",
      "Exploits          Naive Bayes Multinomial      0.62            0.63            0.65            0.6             0.0914         \n",
      "Exploits          SGD Classifier               0.79            0.75            0.73            0.74            0.6082         \n",
      "Exploits          Gradient Boosting Classifier  0.98            0.98            0.99            0.98            2.5647         \n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "mission accomplished!\n",
      "Total operation time: =  62.11910939216614 seconds\n"
     ]
    }
   ],
   "source": [
    "##  \"all_data.csv\" file is required for the operation of the program.\n",
    "##  \"all_data.csv\" file must be located in the same directory as the program.\n",
    "\n",
    "##  the purpose of this program is to apply machine learning algorithms to the dataset and observe the performance of algorithms.\n",
    "##  the algorithms used are:Naive Bayes, QDA, Random Forest, ID3, AdaBoost, MLP, Nearest Neighbors\n",
    "##  As the program display output data include: file name, machine learning algorithm name, accuracy,Precision, Recall, F1-score,Time\n",
    "##  the program will create a CSV file that prints the results and a folder containing graphics.\n",
    "\n",
    "##  the some codes parts used for calculation and graphing are taken from the following site.\n",
    "##  http://scikit-learn.org\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#A√±adimos 5 nuevos algoritmos de clasificaci√≥n (supervisado):\n",
    "from sklearn.linear_model import LogisticRegression #Logistic Regression\n",
    "from sklearn.svm import SVC #Support Vector Machine\n",
    "from sklearn.naive_bayes import MultinomialNB #Naive Bayes Multinomial\n",
    "from sklearn.linear_model import SGDClassifier #Stochastic Gradient Descent Classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier #Gradient Boosting Classifier\n",
    "#from lightgbm import LGBMClassifier\n",
    "#from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "import warnings\n",
    "import math\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "result=\"./results/results_2.csv\" #Archivo CSV donde se guardar√°n los resultados\n",
    "#csv_files=os.listdir(\"attacks\")\n",
    "csv_files = [\n",
    "            #'Generic.csv', \n",
    "            'Exploits.csv',\n",
    "            #'Fuzzers.csv',\n",
    "            #'DoS.csv',\n",
    "            #'Reconnaissance.csv',\n",
    "            #'Analysis.csv',\n",
    "            #'Backdoor.csv',\n",
    "            #'Shellcode.csv',\n",
    "            #'Worms.csv' #Para poder seleccionar los ataques que quedamos,  <----   ######  BORRAR LUEGO  #######\n",
    "]\n",
    "path=\".\\\\attacks\\\\\"\n",
    "repetition=1\n",
    "\n",
    "\n",
    "def folder(f_name):\n",
    "    try:\n",
    "        if not os.path.exists(f_name):\n",
    "            os.makedirs(f_name)\n",
    "    except OSError:\n",
    "        print (\"The folder could not be created!\")\n",
    "\n",
    "#folder_name=\"./results/\"\n",
    "#folder(folder_name)\n",
    "#folder_name=\"./results/result_graph_2/\"\n",
    "#folder(folder_name)\n",
    "\n",
    "\n",
    "ml_list={\n",
    "\"Logistic Regression\":LogisticRegression(penalty='l2', dual=False, solver='newton-cg', class_weight='balanced'),\n",
    "\"Support Vector Machine\":SVC(gamma='auto', kernel='linear', C=5),\n",
    "\"Naive Bayes Multinomial\":MultinomialNB(alpha=0.0, fit_prior=False),\n",
    "\"SGD Classifier\" :SGDClassifier(max_iter=2000, tol=1e-4, loss='squared_hinge', penalty='l1'),\n",
    "\"Gradient Boosting Classifier\":GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "}\n",
    "\n",
    "\n",
    "features={  'Generic': [\"service\",\"dbytes\",\"dsport\",\"Sload\",'Label'], \n",
    "            'Exploits': [\"sttl\",\"dsport\",\"sbytes\",\"dbytes\", 'Label'],\n",
    "            'Fuzzers': [\"sttl\",\"sloss\",\"sport\",\"Sload\", 'Label'],\n",
    "            'DoS': [\"sttl\",\"dsport\",\"dbytes\",\"sbytes\", 'Label'],\n",
    "            'Reconnaissance': [\"sttl\",\"dsport\",\"proto\",\"Dpkts\",'Label'],\n",
    "            'Analysis': [\"sttl\",\"dsport\",\"dstip\",\"proto\", 'Label'],\n",
    "            'Backdoor': [\"sttl\",\"dsport\",\"dbytes\",\"Dload\", 'Label'],\n",
    "            'Shellcode': [\"sttl\",\"dsport\",\"sbytes\",\"dbytes\",'Label'],\n",
    "            'Worms': [\"sttl\",\"dsport\",\"sbytes\",\"sport\",'Label']}\n",
    "\n",
    "seconds=time.time()\n",
    "\n",
    "\n",
    "with open(result, \"w\", newline=\"\",encoding=\"utf-8\") as f:\n",
    "    wrt = csv.writer(f)\n",
    "    wrt.writerow([\"File\",\"ML algorithm\",\"accuracy\",\"Precision\", \"Recall\" , \"F1-score\",\"Time\"])\n",
    "\n",
    "\n",
    "for j in csv_files: \n",
    "    print ('%-17s %-27s  %-15s %-15s %-15s %-15s %-15s' % (\"File\",\"ML algorithm\",\"accuracy\",\"Precision\", \"Recall\" , \"F1-score\",\"Time\"))# print output header\n",
    "    a=[]\n",
    "    \n",
    "    feature_list=list(features[j[0:-4]])\n",
    "    df=pd.read_csv(path+j,usecols=feature_list)\n",
    "    df = df.sample(50000)\n",
    "    df=df.fillna(0)\n",
    "    attack_or_not=[]\n",
    "    for i in df[\"Label\"]:\n",
    "        if i ==\"BENIGN\":\n",
    "            attack_or_not.append(1)\n",
    "        else:\n",
    "            attack_or_not.append(0)\n",
    "    df[\"Label\"]=attack_or_not\n",
    "\n",
    "    \n",
    "    y = df[\"Label\"]\n",
    "    del df[\"Label\"]\n",
    "    feature_list.remove('Label')\n",
    "    X = df[feature_list]\n",
    "\n",
    "    \n",
    "    for ii in ml_list: \n",
    "        precision=[]\n",
    "        recall=[]\n",
    "        f1=[]\n",
    "        accuracy=[]\n",
    "        t_time=[]\n",
    "        for i in range(repetition):\n",
    "            second=time.time()\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y,#  data (X) and labels (y) are divided into 2 parts to be sent to the machine learning algorithm (80% train,%20 test). \n",
    "                test_size = 0.20, random_state = repetition)#  So, in total there are 4 tracks: training data(X_train), training tag (y_train), test data(X_test) and test tag(y_test).\n",
    "            if ii in [\"Naive Bayes Multinomial\", \"SGD Classifier\", \"Logistic Regression\"]:\n",
    "                scaler = MinMaxScaler()\n",
    "                #scaler = StandardScaler()\n",
    "                #scaler = Normalizer()\n",
    "                X_train = scaler.fit_transform(X_train)\n",
    "                X_test = scaler.transform(X_test)\n",
    "\n",
    "            if ii in [\"Support Vector Machine\"]:\n",
    "                #scaler = MinMaxScaler()\n",
    "                scaler = StandardScaler()\n",
    "                #scaler = Normalizer()\n",
    "                X_train = scaler.fit_transform(X_train)\n",
    "                X_test = scaler.transform(X_test)\n",
    "\n",
    "            #machine learning algorithm is applied in this section\n",
    "            clf = ml_list[ii]#choose algorithm from ml_list dictionary                                                                          \n",
    "            clf.fit(X_train, y_train)\n",
    "            predict =clf.predict(X_test)\n",
    "        \n",
    "            #makes \"classification report\" and assigns the precision, f-measure, and recall values.s.    \n",
    "            f_1=f1_score(y_test, predict, average='macro')\n",
    "            pr=precision_score(y_test, predict, average='macro')\n",
    "            rc=recall_score(y_test, predict, average='macro')\n",
    "\n",
    "            \n",
    "            precision.append(float(pr))\n",
    "            recall.append(float(rc))\n",
    "            f1.append(float(f_1))\n",
    "            accuracy.append(clf.score(X_test, y_test))\n",
    "            t_time.append(float((time.time()-second)) )\n",
    "\n",
    "\n",
    "            \n",
    "        print ('%-17s %-27s  %-15s %-15s %-15s %-15s %-15s' % (j[0:-4],ii,str(round(np.mean(accuracy),2)),str(round(np.mean(precision),2)), \n",
    "            str(round(np.mean(recall),2)),str(round(np.mean(f1),2)),str(round(np.mean(t_time),4))))#the result of the ten repetitions is printed on the screen.\n",
    "\n",
    "        with open(result, \"a\", newline=\"\",encoding=\"utf-8\") as f: # all the values found are saved in the opened file.\n",
    "            wrt = csv.writer(f)\n",
    "            for i in range(0,len(t_time)):\n",
    "                wrt.writerow([j[0:-4],ii,accuracy[i],precision[i],recall[i],f1[i],t_time[i]])#file name, algorithm name, precision, recall and f-measure are writed in CSV file\n",
    "        a.append(f1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\n------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "    \n",
    "print(\"mission accomplished!\")\n",
    "print(\"Total operation time: = \",time.time()- seconds ,\"seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
